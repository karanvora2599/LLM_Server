{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"summary\": {\n",
      "        \"text\": \"Fast language models have revolutionized the field of natural language processing (NLP) by enabling efficient and accurate processing of vast amounts of text data. They have numerous applications in various industries and have become a crucial component of many AI-powered systems.\",\n",
      "        \"importance\": \"Fast language models are important because they can process and generate human-like language at high speeds, making them useful for tasks that require quick responses or decisions.\"\n",
      "    },\n",
      "    \"benefits\": [\n",
      "        {\n",
      "            \"name\": \"Improved Accuracy\",\n",
      "            \"description\": \"Fast language models are trained on large datasets and can generate more accurate results than traditional language models.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Faster Processing\",\n",
      "            \"description\": \"They can process large amounts of text data quickly, making them suitable for real-time applications.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Enhanced User Experience\",\n",
      "            \"description\": \"Fast language models can provide quick responses to user queries, leading to a better user experience.\"\n",
      "        }\n",
      "    ],\n",
      "    \"applications\": [\n",
      "        {\n",
      "            \"name\": \"Chatbots\",\n",
      "            \"description\": \"Fast language models are used in chatbots to provide quick and accurate responses to user queries.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Language Translation\",\n",
      "            \"description\": \"They are used in language translation applications to quickly translate text and maintain accuracy.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Question Answering\",\n",
      "            \"description\": \"Fast language models are used in question answering systems to quickly identify and retrieve answers from large text datasets.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "# Modify the prompt to request JSON output\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Explain the importance of fast language models. \"\n",
    "                \"Provide the answer in JSON format with keys 'summary', 'benefits', and 'applications'.\"\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "content = chat_completion.choices[0].message.content\n",
    "\n",
    "# Use regex to extract JSON content in case there is extra text\n",
    "json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "\n",
    "if json_match:\n",
    "    json_content = json_match.group()\n",
    "    try:\n",
    "        data = json.loads(json_content)\n",
    "        print(json.dumps(data, indent=4))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to parse JSON:\", e)\n",
    "        print(\"Content was:\", json_content)\n",
    "else:\n",
    "    print(\"No JSON content found in the response.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Inference Default\n",
    "\n",
    "import requests\n",
    "\n",
    "api_key = \"ljoWc7l91mdURBRNTNPlZQlGpV5OMo\"  # Replace with your actual API key\n",
    "\n",
    "url = \"http://localhost:8000/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": api_key,\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    \"model\": \"llama3.1-8b-8192\",\n",
    "    \"service_name\": \"cerebras\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(result[\"content\"])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Inference Custom Parameters\n",
    "\n",
    "import requests\n",
    "\n",
    "api_key = \"ljoWc7l91mdURBRNTNPlZQlGpV5OMo\"  # Replace with your actual API key\n",
    "\n",
    "url = \"http://localhost:8000/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": api_key,\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "  \"model\": \"llama3.1-8b\",\n",
    "  \"service_name\": \"cerebras\",\n",
    "  \"temperature\": 0.7,\n",
    "  \"max_tokens\": 500,\n",
    "  \"top_p\": 0.9,\n",
    "  \"stop\": [\"\\n\"]\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(result[\"content\"])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
