{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import threading\n",
    "import json\n",
    "from fastapi import FastAPI, HTTPException, Header\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from groq import Groq\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Initialize the master API client with your API key\n",
    "master_client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Thread lock for synchronizing access to api_keys.json\n",
    "api_keys_lock = threading.Lock()\n",
    "\n",
    "# Define the request and response models\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "class ChatCompletionRequest(BaseModel):\n",
    "    messages: List[Message]\n",
    "    model: str\n",
    "\n",
    "class ChatCompletionResponse(BaseModel):\n",
    "    content: str\n",
    "\n",
    "def generate_api_key(length=30):\n",
    "    \"\"\"Generates a random API key of the given length.\"\"\"\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    api_key = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return api_key\n",
    "\n",
    "def load_api_keys():\n",
    "    \"\"\"Loads API keys from the JSON file.\"\"\"\n",
    "    with api_keys_lock:\n",
    "        if not os.path.exists('api_keys.json'):\n",
    "            return {}\n",
    "        with open('api_keys.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "def save_api_keys(api_keys):\n",
    "    \"\"\"Saves API keys to the JSON file.\"\"\"\n",
    "    with api_keys_lock:\n",
    "        with open('api_keys.json', 'w') as f:\n",
    "            json.dump(api_keys, f, indent=4)\n",
    "\n",
    "def add_api_key(client_name):\n",
    "    \"\"\"Generates a new API key, adds it to api_keys.json, and returns the key.\"\"\"\n",
    "    api_keys = load_api_keys()\n",
    "    new_key = generate_api_key()\n",
    "    api_keys[new_key] = client_name\n",
    "    save_api_keys(api_keys)\n",
    "    return new_key\n",
    "\n",
    "@app.post(\"/generate_api_key\")\n",
    "async def generate_api_key_endpoint(client_name: str):\n",
    "    \"\"\"API endpoint to generate a new API key.\"\"\"\n",
    "    new_key = add_api_key(client_name)\n",
    "    return {\"api_key\": new_key}\n",
    "\n",
    "@app.post(\"/chat/completions\", response_model=ChatCompletionResponse)\n",
    "async def chat_completions(\n",
    "    request: ChatCompletionRequest,\n",
    "    api_key: Optional[str] = Header(None),\n",
    "):\n",
    "    # Load the API keys\n",
    "    api_keys = load_api_keys()\n",
    "\n",
    "    # Authenticate the client using the wrapper's API key\n",
    "    if api_key not in api_keys:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid API Key\")\n",
    "\n",
    "    try:\n",
    "        # Forward the request to the master API\n",
    "        chat_completion = master_client.chat.completions.create(\n",
    "            messages=[message.dict() for message in request.messages],\n",
    "            model=request.model,\n",
    "        )\n",
    "\n",
    "        # Extract the response content\n",
    "        content = chat_completion.choices[0].message.content\n",
    "\n",
    "        # Return the response to the client\n",
    "        return ChatCompletionResponse(content=content)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastapi import FastAPI, HTTPException, Header\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from groq import Groq\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Define the request and response models\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "class ChatCompletionRequest(BaseModel):\n",
    "    messages: List[Message]\n",
    "    model: str\n",
    "    service_name: str  # Service to use: 'cerebras' or 'groq'\n",
    "\n",
    "class ChatCompletionResponse(BaseModel):\n",
    "    content: str\n",
    "\n",
    "# API keys for the services\n",
    "SERVICE_API_KEYS = {\n",
    "    \"cerebras\": os.environ.get(\"CEREBRAS_API_KEY\"),\n",
    "    \"groq\": os.environ.get(\"GROQ_API_KEY\"),\n",
    "}\n",
    "\n",
    "# Ensure all necessary API keys are provided\n",
    "for service, api_key in SERVICE_API_KEYS.items():\n",
    "    if not api_key:\n",
    "        raise Exception(f\"API key for {service} not set in environment variables.\")\n",
    "\n",
    "def get_client(service_name: str):\n",
    "    \"\"\"Get the appropriate client based on the service name.\"\"\"\n",
    "    service_name = service_name.lower()\n",
    "    if service_name == \"cerebras\":\n",
    "        return Cerebras(api_key=SERVICE_API_KEYS[\"cerebras\"])\n",
    "    elif service_name == \"groq\":\n",
    "        return Groq(api_key=SERVICE_API_KEYS[\"groq\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported service_name: {service_name}\")\n",
    "\n",
    "@app.post(\"/chat/completions\", response_model=ChatCompletionResponse)\n",
    "async def chat_completions(\n",
    "    request: ChatCompletionRequest,\n",
    "    api_key: Optional[str] = Header(None),\n",
    "):\n",
    "    service_name = request.service_name.lower()\n",
    "\n",
    "    try:\n",
    "        client = get_client(service_name)\n",
    "        messages = [message.dict() for message in request.messages]\n",
    "\n",
    "        if service_name == \"cerebras\":\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=request.model,\n",
    "            )\n",
    "            content = chat_completion  # Adjust as per actual response\n",
    "\n",
    "        elif service_name == \"groq\":\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=request.model,\n",
    "            )\n",
    "            content = chat_completion.choices[0].message.content\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported service_name: {service_name}\")\n",
    "\n",
    "        return ChatCompletionResponse(content=content)\n",
    "\n",
    "    except ValueError as ve:\n",
    "        raise HTTPException(status_code=400, detail=str(ve))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn wrapper_service:app --reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your API Key: ljoWc7l91mdURBRNTNPlZQlGpV5OMo\n"
     ]
    }
   ],
   "source": [
    "#New Key\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/generate_api_key\"\n",
    "data = {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"email\": \"john.doe@example.com\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    api_key = response.json()[\"api_key\"]\n",
    "    print(f\"Your API Key: {api_key}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 400: {\"detail\":\"Model 'llama3.1-8b-8192' is not available for service 'cerebras'.\"}\n"
     ]
    }
   ],
   "source": [
    "#LLM Inference\n",
    "\n",
    "import requests\n",
    "\n",
    "api_key = \"ljoWc7l91mdURBRNTNPlZQlGpV5OMo\"  # Replace with your actual API key\n",
    "\n",
    "url = \"http://localhost:8000/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": api_key,\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    \"model\": \"llama3.1-8b-8192\",\n",
    "    \"service_name\": \"cerebras\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(result[\"content\"])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import json\n",
    "from datetime import datetime\n",
    "from fastapi import FastAPI, HTTPException, Header, Depends\n",
    "from pydantic import BaseModel, EmailStr\n",
    "from typing import List\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from groq import Groq\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text, DateTime, func\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Thread lock for synchronizing access to api_keys.json\n",
    "api_keys_lock = threading.Lock()\n",
    "\n",
    "# Database setup\n",
    "DATABASE_URL = \"postgresql://username:password@host:port/database_name\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the ChatLog model\n",
    "class ChatLog(Base):\n",
    "    __tablename__ = 'chat_logs'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    timestamp = Column(DateTime(timezone=True), server_default=func.now())\n",
    "    client_name = Column(String(100))\n",
    "    client_email = Column(String(100))\n",
    "    service_name = Column(String(50))\n",
    "    model_name = Column(String(100))\n",
    "    client_message = Column(Text)\n",
    "    content_in_response = Column(Text)\n",
    "\n",
    "# Create the tables in the database\n",
    "Base.metadata.create_all(bind=engine)\n",
    "\n",
    "# Master API keys\n",
    "MASTER_SERVICE_API_KEYS = {\n",
    "    \"cerebras\": os.environ.get(\"CEREBRAS_API_KEY\"),\n",
    "    \"groq\": os.environ.get(\"GROQ_API_KEY\"),\n",
    "    # Add more services as needed\n",
    "}\n",
    "\n",
    "for service, api_key in MASTER_SERVICE_API_KEYS.items():\n",
    "    if not api_key:\n",
    "        raise Exception(f\"Master API key for {service} is not set in environment variables.\")\n",
    "\n",
    "# Models\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "class ChatCompletionRequest(BaseModel):\n",
    "    messages: List[Message]\n",
    "    model: str\n",
    "    service_name: str\n",
    "\n",
    "class ChatCompletionResponse(BaseModel):\n",
    "    content: str\n",
    "\n",
    "class GenerateApiKeyRequest(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "\n",
    "def generate_api_key(length=30):\n",
    "    import random\n",
    "    import string\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(characters) for _ in range(length))\n",
    "\n",
    "def load_api_keys():\n",
    "    with api_keys_lock:\n",
    "        if not os.path.exists('api_keys.json'):\n",
    "            return {}\n",
    "        with open('api_keys.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "def save_api_keys(api_keys):\n",
    "    with api_keys_lock:\n",
    "        with open('api_keys.json', 'w') as f:\n",
    "            json.dump(api_keys, f, indent=4)\n",
    "\n",
    "def add_api_key(client_name, client_email):\n",
    "    api_keys = load_api_keys()\n",
    "    new_key = generate_api_key()\n",
    "    api_keys[new_key] = {\n",
    "        \"name\": client_name,\n",
    "        \"email\": client_email\n",
    "    }\n",
    "    save_api_keys(api_keys)\n",
    "    return new_key\n",
    "\n",
    "def authenticate_client(api_key: str = Header(...)):\n",
    "    api_keys = load_api_keys()\n",
    "    if api_key not in api_keys:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid API Key\")\n",
    "    return api_key\n",
    "\n",
    "def get_master_client(service_name: str):\n",
    "    service_name = service_name.lower()\n",
    "    if service_name == \"cerebras\":\n",
    "        api_key = MASTER_SERVICE_API_KEYS[\"cerebras\"]\n",
    "        return Cerebras(api_key=api_key)\n",
    "    elif service_name == \"groq\":\n",
    "        api_key = MASTER_SERVICE_API_KEYS[\"groq\"]\n",
    "        return Groq(api_key=api_key)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported service_name: {service_name}\")\n",
    "\n",
    "def log_to_database(log_entry):\n",
    "    session = SessionLocal()\n",
    "    try:\n",
    "        session.add(log_entry)\n",
    "        session.commit()\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"Error logging to database: {e}\")\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "@app.post(\"/generate_api_key\")\n",
    "async def generate_api_key_endpoint(request: GenerateApiKeyRequest):\n",
    "    client_name = request.name\n",
    "    client_email = request.email\n",
    "\n",
    "    api_keys = load_api_keys()\n",
    "    for key_info in api_keys.values():\n",
    "        if key_info['email'].lower() == client_email.lower():\n",
    "            raise HTTPException(status_code=400, detail=\"An API key has already been generated for this email.\")\n",
    "\n",
    "    new_key = add_api_key(client_name, client_email)\n",
    "    return {\"api_key\": new_key}\n",
    "\n",
    "@app.post(\"/chat/completions\", response_model=ChatCompletionResponse)\n",
    "async def chat_completions(\n",
    "    request: ChatCompletionRequest,\n",
    "    api_key: str = Depends(authenticate_client),\n",
    "):\n",
    "    service_name = request.service_name.lower()\n",
    "    model_name = request.model\n",
    "\n",
    "    try:\n",
    "        client = get_master_client(service_name)\n",
    "        messages = [message.dict() for message in request.messages]\n",
    "\n",
    "        # Retrieve client information\n",
    "        api_keys = load_api_keys()\n",
    "        client_info = api_keys[api_key]\n",
    "        client_name = client_info['name']\n",
    "        client_email = client_info['email']\n",
    "\n",
    "        # Extract client message\n",
    "        client_message = ' '.join(\n",
    "            [msg.content for msg in request.messages if msg.role == 'user']\n",
    "        )\n",
    "\n",
    "        # Process the request\n",
    "        if service_name == \"cerebras\":\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=model_name,\n",
    "            )\n",
    "            content_in_response = chat_completion.get('content', '')\n",
    "\n",
    "        elif service_name == \"groq\":\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=model_name,\n",
    "            )\n",
    "            content_in_response = chat_completion.choices[0].message.content\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported service_name: {service_name}\")\n",
    "\n",
    "        # Log the data to the database\n",
    "        log_entry = ChatLog(\n",
    "            client_name=client_name,\n",
    "            client_email=client_email,\n",
    "            service_name=service_name,\n",
    "            model_name=model_name,\n",
    "            client_message=client_message.strip(),\n",
    "            content_in_response=content_in_response.strip()\n",
    "        )\n",
    "        log_to_database(log_entry)\n",
    "\n",
    "        return ChatCompletionResponse(content=content_in_response)\n",
    "\n",
    "    except ValueError as ve:\n",
    "        raise HTTPException(status_code=400, detail=str(ve))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Recipe'>\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from groq import Groq\n",
    "\n",
    "groq = Groq(\n",
    "    api_key=\"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\"\n",
    ")\n",
    "\n",
    "\n",
    "# Data model for LLM to generate\n",
    "class Ingredient(BaseModel):\n",
    "    name: str\n",
    "    quantity: str\n",
    "    quantity_unit: Optional[str]\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    recipe_name: str\n",
    "    ingredients: List[Ingredient]\n",
    "    directions: List[str]\n",
    "\n",
    "\n",
    "def get_recipe(recipe_name: str) -> Recipe:\n",
    "    chat_completion = groq.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a recipe database that outputs recipes in JSON.\\n\"\n",
    "                # Pass the json schema to the model. Pretty printing improves results.\n",
    "                f\" The JSON object must use the schema: {json.dumps(Recipe.model_json_schema(), indent=2)}\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Fetch a recipe for {recipe_name}\",\n",
    "            },\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "        temperature=0,\n",
    "        # Streaming is not supported in JSON mode\n",
    "        stream=False,\n",
    "        # Enable JSON mode by setting the response format\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return Recipe.model_validate_json(chat_completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "def print_recipe(recipe: Recipe):\n",
    "    print(\"Recipe:\", recipe.recipe_name)\n",
    "\n",
    "    print(\"\\nIngredients:\")\n",
    "    for ingredient in recipe.ingredients:\n",
    "        print(\n",
    "            f\"- {ingredient.name}: {ingredient.quantity} {ingredient.quantity_unit or ''}\"\n",
    "        )\n",
    "    print(\"\\nDirections:\")\n",
    "    for step, direction in enumerate(recipe.directions, start=1):\n",
    "        print(f\"{step}. {direction}\")\n",
    "\n",
    "\n",
    "recipe = get_recipe(\"apple pie\")\n",
    "print(type(recipe))\n",
    "# print_recipe(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
