{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import threading\n",
    "import json\n",
    "from fastapi import FastAPI, HTTPException, Header\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from groq import Groq\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Initialize the master API client with your API key\n",
    "master_client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Thread lock for synchronizing access to api_keys.json\n",
    "api_keys_lock = threading.Lock()\n",
    "\n",
    "# Define the request and response models\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "class ChatCompletionRequest(BaseModel):\n",
    "    messages: List[Message]\n",
    "    model: str\n",
    "\n",
    "class ChatCompletionResponse(BaseModel):\n",
    "    content: str\n",
    "\n",
    "def generate_api_key(length=30):\n",
    "    \"\"\"Generates a random API key of the given length.\"\"\"\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    api_key = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return api_key\n",
    "\n",
    "def load_api_keys():\n",
    "    \"\"\"Loads API keys from the JSON file.\"\"\"\n",
    "    with api_keys_lock:\n",
    "        if not os.path.exists('api_keys.json'):\n",
    "            return {}\n",
    "        with open('api_keys.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "def save_api_keys(api_keys):\n",
    "    \"\"\"Saves API keys to the JSON file.\"\"\"\n",
    "    with api_keys_lock:\n",
    "        with open('api_keys.json', 'w') as f:\n",
    "            json.dump(api_keys, f, indent=4)\n",
    "\n",
    "def add_api_key(client_name):\n",
    "    \"\"\"Generates a new API key, adds it to api_keys.json, and returns the key.\"\"\"\n",
    "    api_keys = load_api_keys()\n",
    "    new_key = generate_api_key()\n",
    "    api_keys[new_key] = client_name\n",
    "    save_api_keys(api_keys)\n",
    "    return new_key\n",
    "\n",
    "@app.post(\"/generate_api_key\")\n",
    "async def generate_api_key_endpoint(client_name: str):\n",
    "    \"\"\"API endpoint to generate a new API key.\"\"\"\n",
    "    new_key = add_api_key(client_name)\n",
    "    return {\"api_key\": new_key}\n",
    "\n",
    "@app.post(\"/chat/completions\", response_model=ChatCompletionResponse)\n",
    "async def chat_completions(\n",
    "    request: ChatCompletionRequest,\n",
    "    api_key: Optional[str] = Header(None),\n",
    "):\n",
    "    # Load the API keys\n",
    "    api_keys = load_api_keys()\n",
    "\n",
    "    # Authenticate the client using the wrapper's API key\n",
    "    if api_key not in api_keys:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid API Key\")\n",
    "\n",
    "    try:\n",
    "        # Forward the request to the master API\n",
    "        chat_completion = master_client.chat.completions.create(\n",
    "            messages=[message.dict() for message in request.messages],\n",
    "            model=request.model,\n",
    "        )\n",
    "\n",
    "        # Extract the response content\n",
    "        content = chat_completion.choices[0].message.content\n",
    "\n",
    "        # Return the response to the client\n",
    "        return ChatCompletionResponse(content=content)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastapi import FastAPI, HTTPException, Header\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from groq import Groq\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Define the request and response models\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "class ChatCompletionRequest(BaseModel):\n",
    "    messages: List[Message]\n",
    "    model: str\n",
    "    service_name: str  # Service to use: 'cerebras' or 'groq'\n",
    "\n",
    "class ChatCompletionResponse(BaseModel):\n",
    "    content: str\n",
    "\n",
    "# API keys for the services\n",
    "SERVICE_API_KEYS = {\n",
    "    \"cerebras\": os.environ.get(\"CEREBRAS_API_KEY\"),\n",
    "    \"groq\": os.environ.get(\"GROQ_API_KEY\"),\n",
    "}\n",
    "\n",
    "# Ensure all necessary API keys are provided\n",
    "for service, api_key in SERVICE_API_KEYS.items():\n",
    "    if not api_key:\n",
    "        raise Exception(f\"API key for {service} not set in environment variables.\")\n",
    "\n",
    "def get_client(service_name: str):\n",
    "    \"\"\"Get the appropriate client based on the service name.\"\"\"\n",
    "    service_name = service_name.lower()\n",
    "    if service_name == \"cerebras\":\n",
    "        return Cerebras(api_key=SERVICE_API_KEYS[\"cerebras\"])\n",
    "    elif service_name == \"groq\":\n",
    "        return Groq(api_key=SERVICE_API_KEYS[\"groq\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported service_name: {service_name}\")\n",
    "\n",
    "@app.post(\"/chat/completions\", response_model=ChatCompletionResponse)\n",
    "async def chat_completions(\n",
    "    request: ChatCompletionRequest,\n",
    "    api_key: Optional[str] = Header(None),\n",
    "):\n",
    "    service_name = request.service_name.lower()\n",
    "\n",
    "    try:\n",
    "        client = get_client(service_name)\n",
    "        messages = [message.dict() for message in request.messages]\n",
    "\n",
    "        if service_name == \"cerebras\":\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=request.model,\n",
    "            )\n",
    "            content = chat_completion  # Adjust as per actual response\n",
    "\n",
    "        elif service_name == \"groq\":\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=request.model,\n",
    "            )\n",
    "            content = chat_completion.choices[0].message.content\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported service_name: {service_name}\")\n",
    "\n",
    "        return ChatCompletionResponse(content=content)\n",
    "\n",
    "    except ValueError as ve:\n",
    "        raise HTTPException(status_code=400, detail=str(ve))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn wrapper_service:app --reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Key\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/generate_api_key\"\n",
    "data = {\"client_name\": \"ClientXYZ\"}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    client_api_key = response.json()[\"api_key\"]\n",
    "    print(f\"Your API Key: {client_api_key}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Inference\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api_key\": \"your_client_api_key\",  # Replace with your generated API key\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    \"model\": \"llama3-8b-8192\",\n",
    "    \"service_name\": \"groq\",  # or \"cerebras\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
